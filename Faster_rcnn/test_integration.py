#!/usr/bin/env python3
"""
é›†æˆæµ‹è¯•è„šæœ¬
éªŒè¯test modeçš„å®Œæ•´åŠŸèƒ½
"""

import os
import sys
import yaml
import torch
import tempfile
import shutil
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_config_modification():
    """æµ‹è¯•é…ç½®æ–‡ä»¶ä¿®æ”¹åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•é…ç½®æ–‡ä»¶ä¿®æ”¹...")
    
    # å¤‡ä»½åŸé…ç½®
    backup_config = None
    with open('config.yaml', 'r', encoding='utf-8') as f:
        backup_config = f.read()
    
    try:
        # æµ‹è¯•å¯ç”¨test mode
        from test_mode_demo import toggle_test_mode
        toggle_test_mode(True)
        
        # éªŒè¯é…ç½®æ˜¯å¦æ­£ç¡®ä¿®æ”¹
        with open('config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        assert config['test_mode']['enabled'] == True, "å¯ç”¨test modeå¤±è´¥"
        print("âœ… å¯ç”¨test modeæˆåŠŸ")
        
        # æµ‹è¯•ç¦ç”¨test mode
        toggle_test_mode(False)
        
        # éªŒè¯é…ç½®æ˜¯å¦æ­£ç¡®ä¿®æ”¹
        with open('config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        assert config['test_mode']['enabled'] == False, "ç¦ç”¨test modeå¤±è´¥"
        print("âœ… ç¦ç”¨test modeæˆåŠŸ")
        
    finally:
        # æ¢å¤åŸé…ç½®
        if backup_config:
            with open('config.yaml', 'w', encoding='utf-8') as f:
                f.write(backup_config)

def test_data_loader_creation():
    """æµ‹è¯•æ•°æ®åŠ è½½å™¨åˆ›å»º"""
    print("\nğŸ§ª æµ‹è¯•æ•°æ®åŠ è½½å™¨åˆ›å»º...")
    
    # åŠ è½½é…ç½®
    with open('config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨
    train_annotations = os.path.join(
        config["convert_output_path"], config["train_annotations"]
    )
    
    if not os.path.exists(train_annotations):
        print("âš ï¸ è·³è¿‡æ•°æ®åŠ è½½å™¨æµ‹è¯•ï¼šæœªæ‰¾åˆ°æ•°æ®é›†")
        return
    
    from dataset import create_data_loaders
    
    # æµ‹è¯•æ­£å¸¸æ¨¡å¼
    config['test_mode']['enabled'] = False
    train_loader_normal, val_loader_normal = create_data_loaders(config)
    normal_train_size = len(train_loader_normal.dataset)
    normal_val_size = len(val_loader_normal.dataset)
    print(f"âœ… æ­£å¸¸æ¨¡å¼ - è®­ç»ƒé›†: {normal_train_size}, éªŒè¯é›†: {normal_val_size}")
    
    # æµ‹è¯•test mode
    config['test_mode']['enabled'] = True
    train_loader_test, val_loader_test = create_data_loaders(config)
    test_train_size = len(train_loader_test.dataset)
    test_val_size = len(val_loader_test.dataset)
    print(f"âœ… æµ‹è¯•æ¨¡å¼ - è®­ç»ƒé›†: {test_train_size}, éªŒè¯é›†: {test_val_size}")
    
    # éªŒè¯test modeç¡®å®å‡å°‘äº†æ•°æ®é›†å¤§å°
    max_train = config['test_mode']['max_train_samples']
    max_val = config['test_mode']['max_val_samples']
    
    assert test_train_size <= max_train, f"è®­ç»ƒé›†å¤§å°è¶…å‡ºé™åˆ¶: {test_train_size} > {max_train}"
    assert test_val_size <= max_val, f"éªŒè¯é›†å¤§å°è¶…å‡ºé™åˆ¶: {test_val_size} > {max_val}"
    assert test_train_size < normal_train_size, "æµ‹è¯•æ¨¡å¼æœªå‡å°‘è®­ç»ƒé›†å¤§å°"
    assert test_val_size < normal_val_size, "æµ‹è¯•æ¨¡å¼æœªå‡å°‘éªŒè¯é›†å¤§å°"
    
    print("âœ… æ•°æ®é›†å¤§å°é™åˆ¶æ­£å¸¸å·¥ä½œ")

def test_batch_processing():
    """æµ‹è¯•æ‰¹æ¬¡å¤„ç†"""
    print("\nğŸ§ª æµ‹è¯•æ‰¹æ¬¡å¤„ç†...")
    
    # åŠ è½½é…ç½®
    with open('config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨
    train_annotations = os.path.join(
        config["convert_output_path"], config["train_annotations"]
    )
    
    if not os.path.exists(train_annotations):
        print("âš ï¸ è·³è¿‡æ‰¹æ¬¡å¤„ç†æµ‹è¯•ï¼šæœªæ‰¾åˆ°æ•°æ®é›†")
        return
    
    from dataset import create_data_loaders
    
    # å¯ç”¨test mode
    config['test_mode']['enabled'] = True
    train_loader, val_loader = create_data_loaders(config)
    
    try:
        # æµ‹è¯•è·å–ä¸€ä¸ªæ‰¹æ¬¡
        images, targets = next(iter(train_loader))
        
        batch_size = len(images)
        expected_batch_size = config['test_mode']['batch_size']
        
        print(f"âœ… æˆåŠŸè·å–æ‰¹æ¬¡ï¼Œå¤§å°: {batch_size}")
        print(f"âœ… å›¾åƒå½¢çŠ¶: {images[0].shape}")
        print(f"âœ… ç›®æ ‡æ•°é‡: {len(targets)}")
        
        # éªŒè¯æ‰¹æ¬¡å¤§å°
        assert batch_size <= expected_batch_size, f"æ‰¹æ¬¡å¤§å°è¶…å‡ºé¢„æœŸ: {batch_size} > {expected_batch_size}"
        
        # éªŒè¯æ•°æ®ç±»å‹
        assert torch.is_tensor(images[0]), "å›¾åƒä¸æ˜¯tensorç±»å‹"
        assert isinstance(targets[0], dict), "ç›®æ ‡ä¸æ˜¯å­—å…¸ç±»å‹"
        assert 'boxes' in targets[0], "ç›®æ ‡ä¸­ç¼ºå°‘boxes"
        assert 'labels' in targets[0], "ç›®æ ‡ä¸­ç¼ºå°‘labels"
        
        print("âœ… æ‰¹æ¬¡æ•°æ®æ ¼å¼æ­£ç¡®")
        
    except Exception as e:
        print(f"âŒ æ‰¹æ¬¡å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        raise

def test_model_integration():
    """æµ‹è¯•æ¨¡å‹é›†æˆ"""
    print("\nğŸ§ª æµ‹è¯•æ¨¡å‹é›†æˆ...")
    
    try:
        from model import create_model
        from utils import get_device
        
        # åŠ è½½é…ç½®
        with open('config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # åˆ›å»ºæ¨¡å‹
        device = get_device(config["device"])
        model = create_model(config, device)
        
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œè®¾å¤‡: {device}")
        
        # æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
        model.eval()
        
        # åˆ›å»ºè™šæ‹Ÿè¾“å…¥
        dummy_input = torch.randn(1, 3, 224, 224).to(device)
        
        with torch.no_grad():
            predictions = model(dummy_input)
        
        print("âœ… æ¨¡å‹å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"âœ… é¢„æµ‹ç»“æœåŒ…å« {len(predictions)} ä¸ªæ£€æµ‹ç»“æœ")
        
        # éªŒè¯è¾“å‡ºæ ¼å¼
        assert isinstance(predictions, list), "é¢„æµ‹ç»“æœåº”è¯¥æ˜¯åˆ—è¡¨"
        assert len(predictions) == 1, "æ‰¹æ¬¡å¤§å°ä¸º1æ—¶åº”è¯¥è¿”å›1ä¸ªé¢„æµ‹ç»“æœ"
        assert 'boxes' in predictions[0], "é¢„æµ‹ç»“æœä¸­ç¼ºå°‘boxes"
        assert 'labels' in predictions[0], "é¢„æµ‹ç»“æœä¸­ç¼ºå°‘labels"
        assert 'scores' in predictions[0], "é¢„æµ‹ç»“æœä¸­ç¼ºå°‘scores"
        
        print("âœ… æ¨¡å‹è¾“å‡ºæ ¼å¼æ­£ç¡®")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        raise

def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹é›†æˆæµ‹è¯•")
    print("=" * 60)
    
    tests = [
        ("é…ç½®æ–‡ä»¶ä¿®æ”¹", test_config_modification),
        ("æ•°æ®åŠ è½½å™¨åˆ›å»º", test_data_loader_creation),
        ("æ‰¹æ¬¡å¤„ç†", test_batch_processing),
        ("æ¨¡å‹é›†æˆ", test_model_integration),
    ]
    
    passed = 0
    failed = 0
    
    for test_name, test_func in tests:
        try:
            print(f"\nğŸ“‹ è¿è¡Œæµ‹è¯•: {test_name}")
            test_func()
            print(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
            passed += 1
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥: {e}")
            failed += 1
            import traceback
            traceback.print_exc()
    
    print("\n" + "=" * 60)
    print(f"ğŸ¯ æµ‹è¯•ç»“æœ: {passed} é€šè¿‡, {failed} å¤±è´¥")
    
    if failed == 0:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼test modeåŠŸèƒ½æ­£å¸¸")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
    
    return failed == 0

if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
